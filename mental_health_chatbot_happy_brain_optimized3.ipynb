{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feef30d5",
   "metadata": {},
   "source": [
    "# Mental Health Chatbot Trainer â€“ Full Pipeline\n",
    "\n",
    "This notebook trains a multi-model chatbot with emotional intelligence and conversational memory.\n",
    "\n",
    "**Models Trained:**\n",
    "- Emotion Classifier: `SamLowe/roberta-base-go_emotions`\n",
    "- Response Generator: `T5`\n",
    "- Q&A Assistant: `T5`\n",
    "\n",
    "**Datasets Used:**\n",
    "- `mental_health_faq_cleaned.csv`\n",
    "- `transformed_mental_health_chatbot.csv`\n",
    "- `Mental Health Chatbot Dataset - Friend mode and Professional mode Responses.csv`\n",
    "- `transformed_mental_health_chatbot_dataset.csv`\n",
    "- HuggingFace datasets:\n",
    "  - `tolu07/Mental_Health_FAQ`\n",
    "  - `Amod/mental_health_counseling_conversations`\n",
    "  - `ruslanmv/ai-medical-chatbot`\n",
    "  - `lavita/ChatDoctor-HealthCareMagic-100k`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0d342",
   "metadata": {},
   "source": [
    "## 1. Load, Clean, and Merge All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0457f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "import gradio as gr\n",
    "from evaluate import load as load_metric\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from accelerate import init_empty_weights\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2914402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "Current Device Index: 0\n",
      "Device Name: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "print(\"GPU Available:\", torch.cuda.is_available())  # True if a GPU is accessible\n",
    "print(\"Current Device Index:\", torch.cuda.current_device())  # e.g., 0\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0))  # e.g., \"NVIDIA GeForce RTX 3070\"\n",
    "\n",
    "# Example: set default tensor type to GPU-based FloatTensor (optional)\n",
    "# This will make ALL newly created tensors go to GPU (Float32).\n",
    "# torch.set_default_dtype(torch.float32)\n",
    "# torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303be4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration Loaded\n"
     ]
    }
   ],
   "source": [
    "# === ðŸ“Š CONFIGURATION CELL ===\n",
    "# Local Dataset Toggles (ds1 through ds4)\n",
    "use_ds1 = True\n",
    "use_ds2 = False\n",
    "use_ds3 = False\n",
    "use_ds4 = False\n",
    "\n",
    "# HuggingFace Dataset Toggles (ds5 through ds8)\n",
    "use_ds5 = False\n",
    "use_ds6 = False\n",
    "use_ds7 = False\n",
    "use_ds8 = False\n",
    "\n",
    "# Sampling fraction for faster development (1.0 = full data)\n",
    "sample_fraction = 0.3\n",
    "\n",
    "# Model Training Configuration\n",
    "train_data_fraction = 0.3  # Train on 10% of the data\n",
    "max_epochs = 3\n",
    "batch_size = 16\n",
    "enable_training = True\n",
    "enable_emotion_labeling = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b9fc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === LOAD ALL DATASETS UNCONDITIONALLY ===\n",
    "# Local (ds1 - ds4)\n",
    "ds1 = pd.read_csv('./data/mental_health_faq_cleaned.csv')\n",
    "ds2 = pd.read_csv('./data/transformed_mental_health_chatbot.csv')\n",
    "ds3 = pd.read_csv('./data/mental_health_chatbot_dataset_merged_modes.csv')\n",
    "ds4 = pd.read_csv('./data/transformed_mental_health_chatbot_dataset.csv')\n",
    "\n",
    "# Hugging Face (ds5 - ds8)\n",
    "ds5 = load_dataset(\"tolu07/Mental_Health_FAQ\")['train']\n",
    "ds6 = load_dataset(\"Amod/mental_health_counseling_conversations\")['train']\n",
    "ds7 = load_dataset(\"ruslanmv/ai-medical-chatbot\")['train']\n",
    "ds8 = load_dataset(\"lavita/ChatDoctor-HealthCareMagic-100k\")['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f2ee1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qa(dataset, question_key, answer_key, drop_cols=None, sample_frac=1.0):\n",
    "    df = dataset['train'].to_pandas() if not isinstance(dataset, pd.DataFrame) else dataset\n",
    "    if sample_frac < 1.0:\n",
    "        df = df.sample(frac=sample_frac, random_state=42)\n",
    "    df = df.rename(columns={question_key: \"question\", answer_key: \"answer\"})\n",
    "    if drop_cols:\n",
    "        df = df.drop(columns=drop_cols, errors='ignore')\n",
    "    return df[[\"question\", \"answer\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e35c68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load and sample HuggingFace datasets ===\n",
    "hf_dfs = []\n",
    "if use_ds5:\n",
    "    ds5 = load_dataset(\"tolu07/Mental_Health_FAQ\")\n",
    "    hf_dfs.append(extract_qa(ds5, question_key=\"Questions\", answer_key=\"Answers\", drop_cols=[\"Question_ID\"], sample_frac=sample_fraction))\n",
    "if use_ds6:\n",
    "    ds6 = load_dataset(\"Amod/mental_health_counseling_conversations\")\n",
    "    hf_dfs.append(extract_qa(ds6, question_key=\"Context\", answer_key=\"Response\", sample_frac=sample_fraction))\n",
    "if use_ds7:\n",
    "    ds7 = load_dataset(\"ruslanmv/ai-medical-chatbot\")\n",
    "    hf_dfs.append(extract_qa(ds7, question_key=\"Patient\", answer_key=\"Doctor\", sample_frac=sample_fraction))\n",
    "if use_ds8:\n",
    "    ds8 = load_dataset(\"lavita/ChatDoctor-HealthCareMagic-100k\")\n",
    "    hf_dfs.append(extract_qa(ds8, question_key=\"input\", answer_key=\"output\", sample_frac=sample_fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94c1d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === APPLY TOGGLES TO INCLUDE/EXCLUDE DATASETS ===\n",
    "# Build lists of selected datasets\n",
    "local_dfs = []\n",
    "if use_ds1: local_dfs.append(ds1)\n",
    "if use_ds2: local_dfs.append(ds2)\n",
    "if use_ds3: local_dfs.append(ds3)\n",
    "if use_ds4: local_dfs.append(ds4)\n",
    "\n",
    "hf_dfs = []\n",
    "if use_ds5: hf_dfs.append(extract_qa(ds5, \"Questions\", \"Answers\", drop_cols=[\"Question_ID\"]))\n",
    "if use_ds6: hf_dfs.append(extract_qa(ds6, \"Context\", \"Response\"))\n",
    "if use_ds7: hf_dfs.append(extract_qa(ds7, \"Patient\", \"Doctor\"))\n",
    "if use_ds8: hf_dfs.append(extract_qa(ds8, \"input\", \"output\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4cf0a3",
   "metadata": {},
   "source": [
    "## 2. Train Emotion Classifier (`SamLowe/roberta-base-go_emotions`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cdf2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"SamLowe/roberta-base-go_emotions\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6d6be77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=28, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "fine_tuned_model.to(device)\n",
    "fine_tuned_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39b67a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and run inference for emotion prediction\n",
    "full_df = pd.read_csv(\"./data/unified_mental_health_chatbot_dataset.csv\")\n",
    "questions = full_df['question'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54ca8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === âš¡ Parallel Tokenization (Optional Upgrade) ===\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def parallel_tokenize(batch_texts, tokenizer, batch_size=32):\n",
    "    def process_batch(batch):\n",
    "        return tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        batches = [batch_texts[i:i + batch_size] for i in range(0, len(batch_texts), batch_size)]\n",
    "        tokenized = list(executor.map(process_batch, batches))\n",
    "    return tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5f73ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 500/22577 [04:34<5:44:31,  1.07it/s]"
     ]
    }
   ],
   "source": [
    "predicted_labels = []\n",
    "batch_size = 16\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(questions), batch_size)):\n",
    "        batch = questions[i:i+batch_size]\n",
    "        batch = [str(q) for q in batch if isinstance(q, str) or pd.notna(q)]  # clean/sanitize\n",
    "        try:\n",
    "            inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "            outputs = fine_tuned_model(**inputs)\n",
    "            probs = torch.sigmoid(outputs.logits)\n",
    "            preds = (probs > 0.5).int().tolist()\n",
    "            predicted_labels.extend([','.join(map(str, [i for i, val in enumerate(p) if val == 1])) for p in preds])\n",
    "        except Exception as e:\n",
    "            print(f\"Error at batch {i}: {e}\")\n",
    "            predicted_labels.extend([\"\"] * len(batch))  # pad with empty if failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cb165",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save emotion-labeled data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpredicted_labels\u001b[49m\n\u001b[0;32m      3\u001b[0m full_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/emotion_labeled_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved labeled dataset to emotion_labeled_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Save emotion-labeled data\n",
    "full_df['label'] = predicted_labels\n",
    "full_df.to_csv(\"./data/emotion_labeled_dataset.csv\", index=False)\n",
    "print(\"Saved labeled dataset to emotion_labeled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare multi-hot encoded dataset for fine-tuning\n",
    "raw_df = pd.read_csv(\"./data/emotion_labeled_dataset.csv\")\n",
    "raw_df['label'] = raw_df['label'].apply(lambda x: list(map(int, str(x).split(','))) if pd.notna(x) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7fca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "multi_hot = mlb.fit_transform(raw_df['label'])\n",
    "label_cols = [f\"label_{i}\" for i in range(multi_hot.shape[1])]\n",
    "raw_df[label_cols] = multi_hot\n",
    "raw_df = raw_df.drop(columns=[\"label\"])\n",
    "raw_df = raw_df.rename(columns={\"question\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c279d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 289443/289443 [01:48<00:00, 2658.51 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72361/72361 [00:27<00:00, 2648.55 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 289443/289443 [01:48<00:00, 2661.18 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72361/72361 [00:27<00:00, 2647.64 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and prepare Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(raw_df)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "def tokenize(batch):\n",
    "    texts = [str(t) if pd.notna(t) else \"\" for t in batch[\"text\"]]\n",
    "    return tokenizer(texts, padding=True, truncation=True)\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)\n",
    "\n",
    "def merge_labels(example):\n",
    "    example['labels'] = torch.tensor([example[f'label_{i}'] for i in range(len(label_cols))])\n",
    "    return example\n",
    "\n",
    "tokenized = tokenized.map(merge_labels)\n",
    "tokenized.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63667d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom Trainer for multi-label classification\n",
    "class MultiLabelTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fct(logits, labels.type_as(logits))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b9958",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set up TrainingArguments\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./saved_models/roberta_emotion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Set up TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./saved_models/roberta_emotion\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    save_total_limit=1,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532219d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train using custom MultiLabelTrainer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MultiLabelTrainer(\n\u001b[0;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mfine_tuned_model,\n\u001b[1;32m----> 4\u001b[0m     args\u001b[38;5;241m=\u001b[39m\u001b[43mtraining_args\u001b[49m,\n\u001b[0;32m      5\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      6\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      7\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_args' is not defined"
     ]
    }
   ],
   "source": [
    "# Train using custom MultiLabelTrainer\n",
    "trainer = MultiLabelTrainer(\n",
    "    model=fine_tuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31348f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "# Save fine-tuned model and tokenizer\n",
    "fine_tuned_model.save_pretrained(\"./saved_models/roberta_emotion\")\n",
    "tokenizer.save_pretrained(\"./saved_models/roberta_emotion\")\n",
    "print(\"Fine-tuned multi-label model saved to ./saved_models/roberta_emotion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4152513",
   "metadata": {},
   "source": [
    "## 3. Train T5 for Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_model_name = \"t5-small\"\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(t5_model_name)\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(t5_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [\"question: \" + q for q in examples[\"question\"]]\n",
    "    model_inputs = tokenizer_t5(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    with tokenizer_t5.as_target_tokenizer():\n",
    "        labels = tokenizer_t5(examples[\"answer\"], max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8bdf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_dataset = Dataset.from_pandas(full_df[['question', 'answer']])\n",
    "t5_dataset = t5_dataset.train_test_split(test_size=0.2)\n",
    "tokenized_t5 = t5_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_t5 = TrainingArguments(\n",
    "    output_dir=\"./saved_models/t5_response_generator\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    save_total_limit=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddaecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_t5 = Trainer(\n",
    "    model=model_t5,\n",
    "    args=args_t5,\n",
    "    train_dataset=tokenized_t5[\"train\"],\n",
    "    eval_dataset=tokenized_t5[\"test\"],\n",
    "    tokenizer=tokenizer_t5,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer_t5, model=model_t5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfe3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer_t5.train()\n",
    "model_t5.save_pretrained(\"./saved_models/t5_response_generator\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bf3292",
   "metadata": {},
   "source": [
    "## 4. Train T5 for Q&A Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e0572",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_df = full_df[full_df['answer'].str.contains(\"Bro|Yo|Hey|Dude|Ugh|memes|suck|spill\", case=False) == False]\n",
    "\n",
    "qa_dataset = Dataset.from_pandas(prof_df[['question', 'answer']])\n",
    "qa_dataset = qa_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "def preprocess_qa(examples):\n",
    "    inputs = [\"question: \" + q for q in examples[\"question\"]]\n",
    "    model_inputs = tokenizer_t5(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    with tokenizer_t5.as_target_tokenizer():\n",
    "        labels = tokenizer_t5(examples[\"answer\"], max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_qa = qa_dataset.map(preprocess_qa, batched=True)\n",
    "model_t5_qa = T5ForConditionalGeneration.from_pretrained(t5_model_name)\n",
    "\n",
    "args_qa = TrainingArguments(\n",
    "    output_dir=\"./saved_models/t5_qa_assistant\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    save_total_limit=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_qa = Trainer(\n",
    "    model=model_t5_qa,\n",
    "    args=args_qa,\n",
    "    train_dataset=tokenized_qa[\"train\"],\n",
    "    eval_dataset=tokenized_qa[\"test\"],\n",
    "    tokenizer=tokenizer_t5,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer_t5, model=model_t5_qa)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf67342",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_qa.train()\n",
    "model_t5_qa.save_pretrained(\"./saved_models/t5_qa_assistant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6109136f",
   "metadata": {},
   "source": [
    "## 5. Emotion-Aware T5 Response Generator & QA Assistant Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c976462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load emotion-enriched dataset\n",
    "df = pd.read_csv(\"./data/t5_emotion_augmented_dataset.csv\")\n",
    "dataset = Dataset.from_pandas(df[[\"emotion_name\", \"question\", \"answer\"]])\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88a01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format input: emotion: [emotion] question: [question]\n",
    "def preprocess(example):\n",
    "    inputs = [f\"emotion: {e} question: {q}\" for e, q in zip(example[\"emotion_name\"], example[\"question\"])]\n",
    "    targets = example[\"answer\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=512, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d54400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize dataset\n",
    "tokenized = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TRAINING: Response Generator\n",
    "# ------------------------\n",
    "model_response = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "args_response = TrainingArguments(\n",
    "    output_dir=\"./saved_models/t5_response_emotion_aware\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    save_total_limit=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c83c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_response = Trainer(\n",
    "    model=model_response,\n",
    "    args=args_response,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model_response)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3751af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_response.train()\n",
    "model_response.save_pretrained(\"./saved_models/t5_response_emotion_aware\")\n",
    "print(\"âœ… Trained and saved: t5_response_emotion_aware\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TRAINING: QA Assistant\n",
    "# ------------------------\n",
    "model_qa = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "args_qa = TrainingArguments(\n",
    "    output_dir=\"./saved_models/t5_qa_emotion_aware\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    save_total_limit=1,\n",
    "    predict_with_generate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00aa167",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_qa = Trainer(\n",
    "    model=model_qa,\n",
    "    args=args_qa,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model_qa)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ba5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer_qa.train()\n",
    "model_qa.save_pretrained(\"./saved_models/t5_qa_emotion_aware\")\n",
    "print(\"âœ… Trained and saved: t5_qa_emotion_aware\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edae096",
   "metadata": {},
   "source": [
    "## 6. Gradio Chatbot Interface (Emotion-Aware with Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e8166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load all models\n",
    "tokenizer_roberta = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "model_roberta = AutoModelForSequenceClassification.from_pretrained(\"./saved_models/roberta_emotion\")\n",
    "id2label = model_roberta.config.id2label\n",
    "\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(\"./saved_models/t5_response_emotion_aware\")\n",
    "model_qa = T5ForConditionalGeneration.from_pretrained(\"./saved_models/t5_qa_emotion_aware\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e6f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "\n",
    "def chatbot_response(user_input):\n",
    "    global chat_history\n",
    "\n",
    "    # Detect Emotion\n",
    "    emo_inputs = tokenizer_roberta(user_input, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        emo_outputs = model_roberta(**emo_inputs)\n",
    "    emotion = id2label[int(torch.argmax(emo_outputs.logits, dim=1))]\n",
    "\n",
    "    # Support message\n",
    "    support_msg = \"I'm here for you.\" if emotion != \"neutral\" else \"Letâ€™s talk more about how you're feeling.\"\n",
    "\n",
    "    # Emotion-aware prompt\n",
    "    prompt = f\"emotion: {emotion} question: {user_input}\"\n",
    "    input_ids = tokenizer_t5(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    # Generate Responses\n",
    "    with torch.no_grad():\n",
    "        response_ids = model_t5.generate(input_ids, max_length=100)\n",
    "        response_text = tokenizer_t5.decode(response_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        qa_ids = model_qa.generate(input_ids, max_length=100)\n",
    "        qa_text = tokenizer_t5.decode(qa_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Chat memory\n",
    "    combined_response = (\n",
    "        f\"Detected Emotion: {emotion}\\n\"\n",
    "        f\"Empathy: {support_msg}\\n\"\n",
    "        f\"Response: {response_text}\\n\"\n",
    "        f\"Answer: {qa_text}\"\n",
    "    )\n",
    "    chat_history.append((f\"You: {user_input}\", f\"{combined_response}\"))\n",
    "    return \"\\n\\n\".join([f\"{q}\\n{a}\" for q, a in chat_history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745647d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chatbot_response, title=\"ðŸ§  Emotion-Aware Mental Health Chatbot\", description=\"Ask any question or share how you're feeling. The bot will respond with empathy and advice.\").launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a8f41",
   "metadata": {},
   "source": [
    "## 7. Evaluate Models (ROUGE, BERTScore, Perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fd5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample evaluation on response generation\n",
    "sample_batch = tokenized_t5[\"test\"].select(range(50))\n",
    "predictions = trainer_t5.predict(sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc32460",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_preds = tokenizer_t5.batch_decode(predictions.predictions, skip_special_tokens=True)\n",
    "decoded_labels = tokenizer_t5.batch_decode(sample_batch[\"labels\"], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE Evaluation\n",
    "rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "# BERTScore Evaluation\n",
    "bertscore_result = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity Calculation\n",
    "losses = []\n",
    "for i in range(len(sample_batch)):\n",
    "    input_ids = torch.tensor([sample_batch[i][\"input_ids\"]]).to(model_t5.device)\n",
    "    labels = torch.tensor([sample_batch[i][\"labels\"]]).to(model_t5.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_t5(input_ids=input_ids, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate perplexity\n",
    "import math\n",
    "perplexity = math.exp(sum(losses)/len(losses))\n",
    "\n",
    "rouge_result, bertscore_result, perplexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
